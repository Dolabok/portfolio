<br>
<body>
<h1>Génération de musique par IA</h1>
<br>
<h2>Présentation</h2>
<p>
  &nbsp;&nbsp;&nbsp;&nbsp;La Génération de musique par IA est un projet personnel visant à créer de la musique de haute qualité en utilisant des modèles de machine learning. Ce projet a permis d'expérimenter diverses architectures et d'acquérir une multitude de connaissances dans le domaine. <br>
  Malgré l'existence de quelques modèles professionnels pour la génération de musique, les modèles actuels, tels que Jukebox d'OpenAI (2018), ceux de Microsoft et Google, offrent des résultats limités. Le modèle le plus performant à ce jour est AIVA, développé par l'entreprise du même nom et commercialisant l'accès à son utilisation.<br>
  Contrairement à ce que l'on peut penser, la génération musicale est bien plus compliquée que la génération d'images, car si on peut tromper le cerveau avec une image imparfaite, la moindre fausse note ou un manque d'harmonie s'entendra tout de suite à l'oreille.<br>
</p>
<br>
<h2>Objectif</h2>
<p>
  &nbsp;&nbsp;&nbsp;&nbsp;L'objectif de ce projet est d'explorer et de créer des modèles de machine learning capables de générer de la musique de qualité supérieure, rivalisant avec les modèles professionnels existants et dépassant leurs limitations dans la limite de mon matériel.
</p>
<br>
<h2>Étapes</h2>
<p>
  Début 2021 : Expérimentation avec un Generative Adversarial Network (GAN) et un Variational Autoencoder (VAE). Les GAN utilisent deux réseaux de neurones, l'un pour générer des données et l'autre pour les évaluer, tandis que les VAE apprennent la structure sous-jacente des données pour générer de nouvelles instances. Les résultats obtenus étaient inférieurs ou comparables à ceux de Jukebox.<br><br>
  Fin 2021 : Exploration d'un Wavenet, une architecture de réseau de neurones convolutifs profonds utilisée pour générer des signaux audio. Bien que les musiques produites soient riches, elles étaient également très bruitées. Des tests ont été réalisés sur un modèle de débruitage pour tenter d'améliorer la qualité sonore.<br><br>
  Début 2022 : Expérimentation avec un LSTM (Long Short-Term Memory) personnalisé. Les LSTM sont des réseaux de neurones récurrents particulièrement adaptés pour traiter les séquences de données temporelles, comme la musique. Cette approche a abouti à la version 1 du modèle, légèrement meilleure que Jukebox, mais produisant des musiques mono canal rappelant les années 90.<br><br>
  Été 2022 : Création de la version 1.5, dérivée du LSTM personnalisé et spécialisée dans la production de musique lo-fi. Cette version intègre des techniques de traitement du signal et des caractéristiques spécifiques au genre lo-fi pour améliorer la génération de musique dans ce style.<br><br>
  Fin 2022 : Mise en place d'une nouvelle architecture pour la version 2 du modèle, combinant des éléments de plusieurs architectures précédemment testées et intégrant de nouvelles techniques pour la gestion de plusieurs instruments, tonalités et rythmes. Malgré ces avancées, la version 2 éprouve des difficultés à produire des mélodies harmonieuses.<br><br>
  2023 : Tests avec la diffusion stable, une méthode de génération de musique qui prend en compte les relations temporelles entre les notes et les instruments pour créer des séquences musicales plus cohérentes et harmonieuses. Cette approche vise à améliorer la qualité globale des mélodies générées par le modèle.<br><br>
  Chacune de ces étapes a permis d'explorer différentes architectures de modèles et de techniques de génération de musique, en se concentrant sur les défis spécifiques liés à la qualité sonore, la complexité des mélodies et la gestion des instruments.
</p>
<br>
<h2>Acteurs</h2>
<p>
  Moi-même et ma machine à café.
</p>
<br>
<h2>Résultats</h2>
<p>
  &nbsp;&nbsp;&nbsp;&nbsp;La chaîne YouTube Mt. Scale publie quotidiennement une vidéo basée sur la version 1 du modèle. D'autres chaînes privées similaires ont été créées pour les autres versions, certaines ayant été fermées par YouTube.
</p>
<br>
<h2>Avenir</h2>
<p>
  &nbsp;&nbsp;&nbsp;&nbsp;Amélioration continue et exploration de nouvelles architectures et techniques pour affiner les modèles de génération de musique par IA. Notament la diffusion stable.
  J'attends que la musique soit suffisement qualitative
</p>
<br>
<h2>Critique</h2>
<p>
  &nbsp;&nbsp;&nbsp;&nbsp;Ce projet a été un terrain d'apprentissage exceptionnel, permettant de mieux comprendre les défis et les possibilités de la génération de musique par IA. Il a également permis d'explorer diverses architectures et techniques pour améliorer ma capacité de création de modèle efficace.
</p>
<br>
<h2>Compétences</h2>
<p>
  - Connaissance approfondie des architectures de machine learning.
  - Expérience dans l'optimisation et l'amélioration des modèles de génération de musique.
  - Capacité à résoudre des problèmes complexes dans le domaine de l'IA et de la musique.
</p>
<br>
<h2>Article lié :</h2>
<a href="skills/autonomy">Autonomie</a><br>
<a href="skills/automation">Automatisation Intelligente</a><br>
</body>
<br>
<br>
<br>
